{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from lib.dataset import *\n",
    "from lib.model import *\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SepsisDataset('./data/processed/sepsis_merged_8_2_0.5_mimic3cv_mimiciv.pt')\n",
    "data_min, data_max = get_data_min_max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = []\n",
    "for i in range(len(data)):\n",
    "    vals = (data[i][2] - data_min) / (data_max - data_min)\n",
    "    data_new.append([vals, data[i][3], data[i][-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4917, 12, 215]) torch.Size([4917, 1])\n"
     ]
    }
   ],
   "source": [
    "data_exter = SepsisDataset('./data/processed/sepsis_merged_8_2_0.5_xjtu.pt')\n",
    "data_train = torch.zeros(len(data_exter), data_exter[0][2].shape[0], data_exter[0][2].shape[1]).cuda()\n",
    "data_train_mask = torch.zeros(len(data_exter), data_exter[0][2].shape[0], data_exter[0][2].shape[1]).cuda()\n",
    "data_label = torch.zeros(len(data_exter), 1)\n",
    "print(data_train.shape, data_label.shape)\n",
    "for i in range(len(data_exter)):\n",
    "    data_train[i,:,:] = (data_exter[i][2] - data_min) / (data_max-data_min)\n",
    "    data_train_mask[i,:,:] = data_exter[i][3]\n",
    "    data_label[i,:] = data_exter[i][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data_new, test_size=0.2, random_state=42)\n",
    "trainset, validset = train_test_split(trainset, test_size=0.125, random_state=42)\n",
    "trainloader = DataLoader(trainset, shuffle=True, batch_size=128)\n",
    "validloader = DataLoader(validset, shuffle=True, batch_size=128)\n",
    "testloader = DataLoader(testset, shuffle=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_size=215, hidden_size=128):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Linear(input_size, hidden_size)\n",
    "        self.key = nn.Linear(input_size, hidden_size)\n",
    "        self.value = nn.Linear(input_size, hidden_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x[0]\n",
    "        print(x.shape)\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        # 计算注意力分数\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1))\n",
    "        scores = scores / (k.size(-1) ** 0.5)  # 进行缩放\n",
    "        # print(k.size(-1) ** 0.5)\n",
    "        # 将分数转换为注意力概率\n",
    "        attn_probs = self.softmax(scores)\n",
    "\n",
    "        # 对值应用注意力加权和\n",
    "        attended_values = torch.matmul(attn_probs, v)\n",
    "        y = self.linear(attended_values)\n",
    "        \n",
    "\n",
    "        return y\n",
    "\n",
    "class SepsisLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, hidden_dim, n_layer, n_classes):\n",
    "        super(SepsisLSTM, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layer = n_layer\n",
    "        self.n_classes = n_classes\n",
    "        self.lstm_val = nn.LSTM(in_dim, hidden_dim, n_layer, batch_first=True)\n",
    "        self.lstm_mask = nn.LSTM(in_dim, hidden_dim, n_layer, batch_first=True)\n",
    "        self.classifier = nn.Sequential(nn.Linear(hidden_dim, 64), nn.ReLU(), nn.Linear(64, n_classes), nn.Sigmoid())\n",
    "        # self.att1 = SelfAttention(215, 128)\n",
    "        # self.att2 = SelfAttention(215, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x[0]\n",
    "        x1 = x[1]\n",
    "\n",
    "        out_val, (h_val, c_val) = self.lstm_val(x0)\n",
    "        out_mask, (h_mask, c_mask) = self.lstm_mask(x1)\n",
    "        y_val = h_val[-1, :, :]\n",
    "        y_mask = h_mask[-1, :, :]\n",
    "        x = self.classifier(y_val * y_mask)\n",
    "        return x\n",
    "    \n",
    "# class SepsisAttention(nn.Module):\n",
    "\n",
    "#     def __init__():\n",
    "#         super(SepsisAttention, self).__init__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, last_epoch=-1):\n",
    "    \"\"\"\n",
    "    Create a schedule with a learning rate that decreases linearly from the initial lr set in the optimizer to 0, after\n",
    "    a warmup period during which it increases linearly from 0 to the initial lr set in the optimizer.\n",
    "    Args:\n",
    "        optimizer (:class:`~torch.optim.Optimizer`):\n",
    "            The optimizer for which to schedule the learning rate.\n",
    "        num_warmup_steps (:obj:`int`):\n",
    "            The number of steps for the warmup phase.\n",
    "        num_training_steps (:obj:`int`):\n",
    "            The total number of training steps.\n",
    "        last_epoch (:obj:`int`, `optional`, defaults to -1):\n",
    "            The index of the last epoch when resuming training.\n",
    "    Return:\n",
    "        :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
    "    \"\"\"\n",
    "    def lr_lambda(current_step: int):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        return max(\n",
    "            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        )\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SepsisLSTM(\n",
       "  (lstm_val): LSTM(215, 1024, num_layers=2, batch_first=True)\n",
       "  (lstm_mask): LSTM(215, 1024, num_layers=2, batch_first=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SepsisLSTM(in_dim=215, hidden_dim=1024, n_layer=2, n_classes=1)\n",
    "\n",
    "model.to(device)\n",
    "loss = nn.BCELoss()\n",
    "optim = torch.optim.Adamax(lr=1e-4, params=model.parameters())\n",
    "scheduler = get_linear_schedule_with_warmup(optim, 0, 11700)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7168186715606971 0.6771305253910718\n",
      "0.7302860023544442 0.6107000514047599\n",
      "0.7852997162146451 0.7320803271368476\n",
      "0.8484454879352392 0.7794511540583777\n",
      "0.862316091415693 0.7540336020967052\n",
      "0.8703078805154922 0.7797872875664364\n",
      "0.8750534833487331 0.7726358030678017\n",
      "0.8587166443946861 0.6586411964300669\n",
      "0.8771869335413202 0.7723936744009923\n",
      "0.8787776660125498 0.7632238993406752\n",
      "0.8660478052881324 0.7884617166939026\n",
      "0.876840497944686 0.7963460417507277\n",
      "0.8839040655817648 0.7907909845385206\n",
      "0.8793483904159722 0.7395024065570364\n",
      "0.8813867590997004 0.7790029760476327\n",
      "0.8830485673523047 0.8038818206884133\n",
      "0.8861361275372523 0.7959149931432736\n",
      "0.8890974223026387 0.7985387708734606\n",
      "0.8854629080914834 0.8059476101751635\n",
      "0.8878259424719215 0.7945351245448296\n",
      "0.889278759685252 0.8034179200369664\n",
      "0.8899024378993012 0.7939420499874055\n",
      "0.8913218353743694 0.8028406508709846\n",
      "0.888864778561285 0.7968779635108955\n",
      "0.8903931432111096 0.811156852042669\n",
      "0.8928751471527561 0.8072429902675199\n",
      "0.8921514450741896 0.8047242232270737\n",
      "0.893207932433762 0.8122363354529659\n",
      "0.8953310272144932 0.8111590863126634\n",
      "0.8944667033499287 0.8115751570360803\n",
      "0.8954800039350566 0.8096361416838318\n",
      "0.8957191198088201 0.8123072528376056\n",
      "0.8959951856748882 0.808558065036124\n",
      "0.8949535253822911 0.8129264766290394\n",
      "0.8975755627342619 0.8129800991089069\n",
      "0.8944261054284481 0.8115276581110124\n",
      "0.8961780528342529 0.8116157048989431\n",
      "0.8971797035810426 0.8143289361796499\n",
      "0.897648992018331 0.8149924316172705\n",
      "0.8973957551284 0.8119374397781486\n",
      "0.8983601028574818 0.8159632633052433\n",
      "0.890443743519042 0.802301943550093\n",
      "0.8989174122955452 0.8149169629419014\n",
      "0.8990693308944769 0.8142907053375221\n",
      "0.8977556056903929 0.8132513560363852\n",
      "0.8994134129884165 0.8153215313123837\n",
      "0.899324685936833 0.8151372454132093\n",
      "0.8995515635965852 0.8152554134706952\n",
      "0.8993465735118921 0.8151160612236319\n",
      "0.8995266164680231 0.8152589717525383\n",
      "0.8995261457674844 0.8152589717525383\n",
      "0.8995273225188316 0.8152589717525383\n",
      "0.8995268518182928 0.8152589717525383\n",
      "0.899525910417215 0.8152589717525383\n",
      "0.8995273225188316 0.8152589717525383\n",
      "0.8995266164680232 0.8152589717525383\n",
      "0.8995259104172149 0.8152589717525383\n",
      "0.8995256750669455 0.8152589717525383\n",
      "0.8995261457674844 0.8152589717525383\n",
      "0.8995268518182926 0.8152589717525383\n",
      "0.8995268518182928 0.8152589717525383\n",
      "0.8995266164680231 0.8152589717525383\n",
      "0.8995270871685621 0.8152589717525383\n",
      "0.8995263811177538 0.8152589717525383\n",
      "0.8995266164680231 0.8152589717525383\n",
      "0.8995273225188316 0.8152589717525383\n",
      "0.8995275578691011 0.8152589717525383\n",
      "0.899527557869101 0.8152589717525383\n",
      "0.8995270871685621 0.8152589717525383\n",
      "0.8995259104172149 0.8152589717525383\n",
      "0.8995268518182927 0.8152589717525383\n",
      "0.8995263811177537 0.8152589717525383\n",
      "0.8995270871685621 0.8152589717525383\n",
      "0.8995266164680233 0.8152589717525383\n",
      "0.8995270871685622 0.8152589717525383\n",
      "0.8995263811177537 0.8152589717525383\n",
      "0.8995266164680232 0.8152589717525383\n",
      "0.8995266164680231 0.8152589717525383\n",
      "0.8995266164680231 0.8152589717525383\n",
      "0.8995263811177538 0.8152589717525383\n",
      "0.8995273225188316 0.8152589717525383\n",
      "0.8995270871685621 0.8152589717525383\n",
      "0.8995266164680231 0.8152589717525383\n",
      "0.8995268518182928 0.8152589717525383\n",
      "0.8995261457674844 0.8152589717525383\n",
      "0.8995261457674844 0.8152589717525383\n",
      "0.899527557869101 0.8152589717525383\n",
      "0.8995268518182926 0.8152589717525383\n",
      "0.8995266164680232 0.8152589717525383\n",
      "0.8995252043664066 0.8152589717525383\n",
      "0.8995270871685621 0.8152589717525383\n",
      "0.899527087168562 0.8152589717525383\n",
      "0.8995266164680233 0.8152589717525383\n",
      "0.8995273225188316 0.8152589717525383\n",
      "0.899527557869101 0.8152589717525383\n",
      "0.8995273225188316 0.8152589717525383\n",
      "0.899525910417215 0.8152589717525383\n",
      "0.8995268518182926 0.8152589717525383\n",
      "0.8995263811177538 0.8152589717525383\n",
      "0.8995252043664066 0.8152589717525383\n"
     ]
    }
   ],
   "source": [
    "auc_best = 0\n",
    "for i in range(100):\n",
    "\n",
    "    for vals,masks,label in trainloader:\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        y_pred = model((vals,masks))\n",
    "        error = loss(y_pred, label.reshape(-1,1))\n",
    "        # print(error)\n",
    "        error.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_all = []\n",
    "        y_label_all = []\n",
    "        model.eval()\n",
    "        for vals,masks,label in validloader:\n",
    "            y_pred_all.append(model((vals,masks)))\n",
    "            y_label_all.append(label.reshape(-1,1))\n",
    "        y_pred_all = torch.concat((y_pred_all))\n",
    "        y_label_all = torch.concat((y_label_all))\n",
    "        auc = roc_auc_score(y_label_all.cpu(), y_pred_all.cpu())\n",
    "        if auc > auc_best:\n",
    "            auc_best = auc\n",
    "            torch.save(model.state_dict, '1.pt')\n",
    "        print(auc, end=' ')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        a = model((data_train,data_train_mask)).cpu()\n",
    "        b = data_label.cpu()\n",
    "        print(roc_auc_score(b, a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075913641513529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(auc_best)\n",
    "model_dict = torch.load('1.pt')\n",
    "model_best = model\n",
    "model_best.load_state_dict(model_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9197170327119746\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred_all = []\n",
    "    y_label_all = []\n",
    "    model.eval()\n",
    "    for vals,masks,label in trainloader:\n",
    "        y_pred_all.append(model_best((vals,masks)))\n",
    "        y_label_all.append(label.reshape(-1,1))\n",
    "    y_pred_all = torch.concat((y_pred_all))\n",
    "    y_label_all = torch.concat((y_label_all))\n",
    "    auc = roc_auc_score(y_label_all.cpu(), y_pred_all.cpu())\n",
    "    if auc > auc_best:\n",
    "        auc_best = auc\n",
    "        model_best = model\n",
    "    print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9088249667330663\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred_all = []\n",
    "    y_label_all = []\n",
    "    model.eval()\n",
    "    for vals,masks,label in testloader:\n",
    "        y_pred_all.append(model_best((vals,masks)))\n",
    "        y_label_all.append(label.reshape(-1,1))\n",
    "    y_pred_all = torch.concat((y_pred_all))\n",
    "    y_label_all = torch.concat((y_label_all))\n",
    "    auc = roc_auc_score(y_label_all.cpu(), y_pred_all.cpu())\n",
    "    if auc > auc_best:\n",
    "        auc_best = auc\n",
    "        model_best = model\n",
    "    print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23454, 12, 215]) torch.Size([23454, 1])\n",
      "0.8922810475125396\n"
     ]
    }
   ],
   "source": [
    "data_exter = SepsisDataset('./data/processed/sepsis_merged_8_2_0.5_eicu.pt')\n",
    "data_train = torch.zeros(len(data_exter), data_exter[0][2].shape[0], data_exter[0][2].shape[1]).cuda()\n",
    "data_train_mask = torch.zeros(len(data_exter), data_exter[0][2].shape[0], data_exter[0][2].shape[1]).cuda()\n",
    "data_label = torch.zeros(len(data_exter), 1)\n",
    "print(data_train.shape, data_label.shape)\n",
    "for i in range(len(data_exter)):\n",
    "    data_train[i,:,:] = (data_exter[i][2] - data_min) / (data_max-data_min)\n",
    "    data_train_mask[i,:,:] = data_exter[i][3]\n",
    "    data_label[i,:] = data_exter[i][-2]\n",
    "\n",
    "with torch.no_grad():\n",
    "    a = model_best((data_train,data_train_mask)).cpu()\n",
    "    b = data_label.cpu()\n",
    "print(roc_auc_score(b, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4917, 12, 215]) torch.Size([4917, 1])\n",
      "0.7952823637318731\n"
     ]
    }
   ],
   "source": [
    "data_exter = SepsisDataset('./data/processed/sepsis_merged_8_2_0.5_xjtu.pt')\n",
    "data_train = torch.zeros(len(data_exter), data_exter[0][2].shape[0], data_exter[0][2].shape[1]).cuda()\n",
    "data_train_mask = torch.zeros(len(data_exter), data_exter[0][2].shape[0], data_exter[0][2].shape[1]).cuda()\n",
    "data_label = torch.zeros(len(data_exter), 1)\n",
    "print(data_train.shape, data_label.shape)\n",
    "for i in range(len(data_exter)):\n",
    "    data_train[i,:,:] = (data_exter[i][2] - data_min) / (data_max-data_min)\n",
    "    data_train_mask[i,:,:] = data_exter[i][3]\n",
    "    data_label[i,:] = data_exter[i][-2]\n",
    "\n",
    "with torch.no_grad():\n",
    "    a = model_best((data_train,data_train_mask)).cpu()\n",
    "    b = data_label.cpu()\n",
    "print(roc_auc_score(b, a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('pytorch1.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da3e02d254dc34bc3d10ac39b4ec8026e7231600f32bf8dc70a498a6f4695c12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
